{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "617d82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e351c",
   "metadata": {},
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "068bee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8f9eb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['name'], df['sex']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.67)\n",
    "train_data = tuple((x, y) for x, y in zip(X_train, y_train))\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]\n",
    "n = df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e93ead1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "def train(samples):\n",
    "    classes, freq = defaultdict(lambda:0), defaultdict(lambda:0)\n",
    "    for feats, label in samples:\n",
    "        classes[label] += 1                 # count classes frequencies\n",
    "        for feat in feats:\n",
    "            freq[label, feat] += 1          # count features frequencies\n",
    "\n",
    "    for label, feat in freq:                # normalize features frequencies\n",
    "        freq[label, feat] /= classes[label]\n",
    "    for c in classes:                       # normalize classes frequencies\n",
    "        classes[c] /= len(samples)\n",
    "#     print(classes, freq)\n",
    "    return classes, freq                    # return P(C) and P(O|C)\n",
    "\n",
    "def classify(classifier, feats):\n",
    "    classes, prob = classifier\n",
    "    return min(classes.keys(),              # calculate argmin(-log(P(C|O))) -> argmax(P(C|O))\n",
    "        key = lambda cl: -log(classes[cl]) + sum(-log(prob.get((cl,feat))) for feat in feats))\n",
    "\n",
    "def get_features(sample): return (sample[-1]) # get last letter\n",
    "\n",
    "features = [(get_features(feat), label) for feat, label in train_data]\n",
    "classifier = train(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b3bb1dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m genders \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[name, true_gender, classify(classifier, get_features(name))] \u001b[38;5;28;01mfor\u001b[39;00m name, true_gender \u001b[38;5;129;01min\u001b[39;00m test_data])\n",
      "Cell \u001b[1;32mIn[210], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m genders \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[name, true_gender, classify(classifier, get_features(name))] \u001b[38;5;28;01mfor\u001b[39;00m name, true_gender \u001b[38;5;129;01min\u001b[39;00m test_data])\n",
      "Cell \u001b[1;32mIn[209], line 20\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(classifier, feats)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify\u001b[39m(classifier, feats):\n\u001b[0;32m     19\u001b[0m     classes, prob \u001b[38;5;241m=\u001b[39m classifier\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(classes\u001b[38;5;241m.\u001b[39mkeys(),              \u001b[38;5;66;03m# calculate argmin(-log(P(C|O))) -> argmax(P(C|O))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m cl: \u001b[38;5;241m-\u001b[39mlog(classes[cl]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m-\u001b[39mlog(prob\u001b[38;5;241m.\u001b[39mget((cl,feat))) \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m feats))\n",
      "Cell \u001b[1;32mIn[209], line 21\u001b[0m, in \u001b[0;36mclassify.<locals>.<lambda>\u001b[1;34m(cl)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify\u001b[39m(classifier, feats):\n\u001b[0;32m     19\u001b[0m     classes, prob \u001b[38;5;241m=\u001b[39m classifier\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(classes\u001b[38;5;241m.\u001b[39mkeys(),              \u001b[38;5;66;03m# calculate argmin(-log(P(C|O))) -> argmax(P(C|O))\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m cl: \u001b[38;5;241m-\u001b[39mlog(classes[cl]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m-\u001b[39mlog(prob\u001b[38;5;241m.\u001b[39mget((cl,feat))) \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m feats))\n",
      "Cell \u001b[1;32mIn[209], line 21\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify\u001b[39m(classifier, feats):\n\u001b[0;32m     19\u001b[0m     classes, prob \u001b[38;5;241m=\u001b[39m classifier\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(classes\u001b[38;5;241m.\u001b[39mkeys(),              \u001b[38;5;66;03m# calculate argmin(-log(P(C|O))) -> argmax(P(C|O))\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m cl: \u001b[38;5;241m-\u001b[39mlog(classes[cl]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m-\u001b[39mlog(prob\u001b[38;5;241m.\u001b[39mget((cl,feat))) \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m feats))\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "genders = np.array([[name, true_gender, classify(classifier, get_features(name))] for name, true_gender in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7b6e3",
   "metadata": {},
   "source": [
    "Судя по всему, в тестовой выборке встречается имя, которое заканчивается на букву, которой не было в тренировочной выборке, а исходный алгоритм не умеет это обрабатывать. Перепишем его так, чтобы это не вызывало ошибки: если буква не встречалась в тренировочных данных, логарифм будет зануляться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c142342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных классификаций (accuracy): 0.7791754756871035\n"
     ]
    }
   ],
   "source": [
    "def classify2(classifier, feats):\n",
    "    classes, prob = classifier\n",
    "    return min(classes.keys(),              \n",
    "        key = lambda cl: -log(classes[cl]) + sum(-log(prob.get((cl,feat), 1/n)) for feat in feats))\n",
    "\n",
    "#в genders лежат имя, настоящий пол и пол, предсказаный с помощью нашего классификатора\n",
    "genders = np.array([[name, true_gender, classify2(classifier, get_features(name))] for name, true_gender in test_data])\n",
    "y_pred = genders[:, 2]\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Доля правильных классификаций (accuracy):', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f5471",
   "metadata": {},
   "source": [
    "Чтобы оценить, насколько хорошо классификатор справился с задачей, мы можем также использовать метрики precision - отношение числа верно определенных мальчиков (девочек) к общему числу имен, определенных как мальчики (девочки) (в общем случае число верно определенных positive ко всем, определенным как positive), которая показывает точность модели при определении класса boy (girl), и recall - отношение числа верно определенных мальчиков (девочек) к общему числу имен мальчиков (девочек) (в общем случае число верно определенных positive ко всем positive), показывающая способность модели обнаруживать выборки, относящиеся к классу boy (girl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "25e30b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2dfcb189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive \t boy \t girl\n",
      "precision\t 0.750 \t 0.817\n",
      "recall\t\t 0.840 \t 0.718\n"
     ]
    }
   ],
   "source": [
    "precision_boy = precision_score(y_test, y_pred, pos_label='boy')\n",
    "recall_boy = recall_score(y_test, y_pred, pos_label='boy')\n",
    "precision_girl = precision_score(y_test, y_pred, pos_label='girl')\n",
    "recall_girl = recall_score(y_test, y_pred, pos_label='girl')\n",
    "print('positive \\t boy \\t girl')\n",
    "print(f'precision\\t {precision_boy:.3f} \\t {precision_girl:.3f}')\n",
    "print(f'recall\\t\\t {recall_boy:.3f} \\t {recall_girl:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1ea63",
   "metadata": {},
   "source": [
    "Теперь построим другую модель - тоже наивный байесовский классификатор, но определение пола происходит на основе первых двух букв имени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f6d6d96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'se'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features2(sample): return sample[0] + sample[-1]\n",
    "get_features2('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2720779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных классификаций (accuracy): 0.7825581395348837\n",
      "positive \t boy \t girl\n",
      "precision\t 0.766 \t 0.801\n",
      "recall\t\t 0.815 \t 0.750\n"
     ]
    }
   ],
   "source": [
    "features2 = [(get_features2(feat), label) for feat, label in train_data]\n",
    "classifier2 = train(features2)\n",
    "genders2 = np.array([[name, true_gender, classify2(classifier2, get_features2(name))] for name, true_gender in test_data])\n",
    "y_pred2 = genders2[:, 2]\n",
    "print('Доля правильных классификаций (accuracy):', accuracy_score(y_test, y_pred2))\n",
    "precision_boy2 = precision_score(y_test, y_pred2, pos_label='boy')\n",
    "recall_boy2 = recall_score(y_test, y_pred2, pos_label='boy')\n",
    "precision_girl2 = precision_score(y_test, y_pred2, pos_label='girl')\n",
    "recall_girl2 = recall_score(y_test, y_pred2, pos_label='girl')\n",
    "print('positive \\t boy \\t girl')\n",
    "print(f'precision\\t {precision_boy2:.3f} \\t {precision_girl2:.3f}')\n",
    "print(f'recall\\t\\t {recall_boy2:.3f} \\t {recall_girl2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1859b24",
   "metadata": {},
   "source": [
    "Как мы видим, при добавлении первой буквы имени точность алгоритма классификации не сильно улучшилась, что говорит нам о незначительном влиянии первой буквы на принадлежность имени к определенному полу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddef59",
   "metadata": {},
   "source": [
    "Модифицируем classify: вместо логарифмов будем брать исходные вероятности, вместо минимума максимум, вместо суммы - произведение. По свойствам логарифма, максимум новой функции будет в той же точке, что и минимум старой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "48796593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify3(classifier, feats):\n",
    "    classes, prob = classifier\n",
    "    return max(classes.keys(),              \n",
    "        key = lambda cl: classes[cl] * np.prod([prob.get((cl,feat), 1/n) for feat in feats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "626b6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных классификаций (accuracy): 0.7825581395348837\n",
      "positive \t boy \t girl\n",
      "precision\t 0.766 \t 0.801\n",
      "recall\t\t 0.815 \t 0.750\n"
     ]
    }
   ],
   "source": [
    "genders3 = np.array([[name, true_gender, classify3(classifier2, get_features2(name))] for name, true_gender in test_data])\n",
    "y_pred3 = genders3[:, 2]\n",
    "print('Доля правильных классификаций (accuracy):', accuracy_score(y_test, y_pred3))\n",
    "precision_boy3 = precision_score(y_test, y_pred3, pos_label='boy')\n",
    "recall_boy3 = recall_score(y_test, y_pred3, pos_label='boy')\n",
    "precision_girl3 = precision_score(y_test, y_pred3, pos_label='girl')\n",
    "recall_girl3 = recall_score(y_test, y_pred3, pos_label='girl')\n",
    "print('positive \\t boy \\t girl')\n",
    "print(f'precision\\t {precision_boy3:.3f} \\t {precision_girl3:.3f}')\n",
    "print(f'recall\\t\\t {recall_boy3:.3f} \\t {recall_girl3:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605df9e",
   "metadata": {},
   "source": [
    "Видим, что результаты не изменились, как и ожидалось. Итого, можно сделать вывод, что изменение целевых признаков и классифицирующей функции (кроме тождественного, как в примере выше) влияют на долю правильных классификаций алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361e14f",
   "metadata": {},
   "source": [
    "Применим Гауссовский классификатор (основываясь на последней букве имени). Для этого нужно сначала закодировать буквы в числа с помощью preprocessing.LabelEncoder()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8b50ad7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных классификаций (accuracy): 0.733697439511393\n",
      "positive \t boy \t girl\n",
      "precision\t 0.743 \t 0.725\n",
      "recall\t\t 0.717 \t 0.750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X_train_coded = le.fit_transform([get_features(x) for x in X_train]).reshape(-1, 1)\n",
    "X_test_coded = le.fit_transform([get_features(x) for x in X_test]).reshape(-1, 1)\n",
    "\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train_coded, y_train)\n",
    "y_pred_gnb = GNB.predict(X_test_coded)\n",
    "\n",
    "print('Доля правильных классификаций (accuracy):', accuracy_score(y_test, y_pred_gnb))\n",
    "precision_boy_gnb = precision_score(y_test, y_pred_gnb, pos_label='boy')\n",
    "recall_boy_gnb = recall_score(y_test, y_pred_gnb, pos_label='boy')\n",
    "precision_girl_gnb = precision_score(y_test, y_pred_gnb, pos_label='girl')\n",
    "recall_girl_gnb = recall_score(y_test, y_pred_gnb, pos_label='girl')\n",
    "print('positive \\t boy \\t girl')\n",
    "print(f'precision\\t {precision_boy_gnb:.3f} \\t {precision_girl_gnb:.3f}')\n",
    "print(f'recall\\t\\t {recall_boy_gnb:.3f} \\t {recall_girl_gnb:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d6c69",
   "metadata": {},
   "source": [
    "Как мы видим, результаты гауссовского классификатора оказались неплохими, но чуть хуже, чем наивного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e1896d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных классификаций (accuracy): 0.4986845196147522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive \t boy \t girl\n",
      "precision\t 0.000 \t 0.499\n",
      "recall\t\t 0.000 \t 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train_coded, y_train)\n",
    "y_pred_mnb = MNB.predict(X_test_coded)\n",
    "\n",
    "print('Доля правильных классификаций (accuracy):', accuracy_score(y_test, y_pred_mnb))\n",
    "precision_boy_mnb = precision_score(y_test, y_pred_mnb, pos_label='boy')\n",
    "recall_boy_mnb = recall_score(y_test, y_pred_mnb, pos_label='boy')\n",
    "precision_girl_mnb = precision_score(y_test, y_pred_mnb, pos_label='girl')\n",
    "recall_girl_mnb = recall_score(y_test, y_pred_mnb, pos_label='girl')\n",
    "print('positive \\t boy \\t girl')\n",
    "print(f'precision\\t {precision_boy_mnb:.3f} \\t {precision_girl_mnb:.3f}')\n",
    "print(f'recall\\t\\t {recall_boy_mnb:.3f} \\t {recall_girl_mnb:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262686a",
   "metadata": {},
   "source": [
    "Видим, что Мультиномиальный классификатор в нашем случае вообще не работает. \n",
    "\n",
    "Таким образом, в конкретной задаче для условия классификации по последней букве наивный байесовский классификатор оказался точнее остальных рассматриваемых."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfadcbb8",
   "metadata": {},
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "812f3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0b910bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8e2e4ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n",
      "precision\t [1. 1. 1.]\n",
      "recall\t\t [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_iris_train, y_iris_train)\n",
    "y_iris_pred = LDA.predict(X_iris_test)\n",
    "\n",
    "print('accuracy:', accuracy_score(y_iris_test, y_iris_pred))\n",
    "precision_iris = precision_score(y_iris_test, y_iris_pred, average=None)\n",
    "recall_iris = recall_score(y_iris_test, y_iris_pred, average=None)\n",
    "print(f'precision\\t {precision_iris}')\n",
    "print(f'recall\\t\\t {recall_iris}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20f128",
   "metadata": {},
   "source": [
    "Видим, что встроенный LDA идеально отрабатывает на этом датасете\n",
    "\n",
    "Реализуем свой LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1e1571c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_dimensionality(X, y, k):\n",
    "    '''\n",
    "    X - набор данных, y - метка, k - целевой размер\n",
    "    '''\n",
    "    label_ = list(set(y))\n",
    "\n",
    "    X_classify = {}\n",
    "\n",
    "    for label in label_:\n",
    "        X1 = np.array([X[i] for i in range(len(X)) if y[i] == label])\n",
    "        X_classify[label] = X1\n",
    "\n",
    "    mju = np.mean(X, axis=0)\n",
    "    mju_classify = {}\n",
    "\n",
    "    for label in label_:\n",
    "        mju1 = np.mean(X_classify[label], axis=0)\n",
    "        mju_classify[label] = mju1\n",
    "\n",
    "    #St = np.dot((X - mju).T, X - mju)\n",
    "\n",
    "    Sw = np.zeros((len(mju), len(mju)))  # Вычислить матрицу внутриклассовой дивергенции\n",
    "    for i in label_:\n",
    "        Sw += np.dot((X_classify[i] - mju_classify[i]).T,\n",
    "                     X_classify[i] - mju_classify[i])\n",
    "\n",
    "    # Sb=St-Sw\n",
    "\n",
    "    Sb = np.zeros((len(mju), len(mju)))  # Вычислить матрицу внутриклассовой дивергенции\n",
    "    for i in label_:\n",
    "        Sb += len(X_classify[i]) * np.dot((mju_classify[i] - mju).reshape(\n",
    "            (len(mju), 1)), (mju_classify[i] - mju).reshape((1, len(mju))))\n",
    "\n",
    "    eig_vals, eig_vecs = np.linalg.eig(\n",
    "        np.linalg.inv(Sw).dot(Sb))  # Вычислить собственное значение и собственную матрицу Sw-1 * Sb\n",
    "\n",
    "    sorted_indices = np.argsort(eig_vals)\n",
    "    topk_eig_vecs = eig_vecs[:, sorted_indices[:-k - 1:-1]]  # Извлекаем первые k векторов признаков\n",
    "    return topk_eig_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872707d",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e4a7f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c6a5219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "KNC = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ac1b70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_max_acc = 0\n",
    "kfold_max_acc_k = 0\n",
    "for k in range(1, 51):\n",
    "    KNC.n_neighbors = k\n",
    "    curr_score = cross_val_score(KNC, wine.data, wine.target, cv=KFold(shuffle=True, random_state=42), scoring='accuracy').mean()\n",
    "#     print(curr_score)\n",
    "    if kfold_max_acc < curr_score:\n",
    "        kfold_max_acc = curr_score\n",
    "        kfold_max_acc_k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b25d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOO_max_acc = 0\n",
    "LOO_max_acc_k = 0\n",
    "for k in range(1, 51):\n",
    "    KNC.n_neighbors = k\n",
    "    curr_score = cross_val_score(KNC, wine.data, wine.target, cv=LeaveOneOut(), scoring='accuracy').mean()\n",
    "#     print(curr_score)\n",
    "    if LOO_max_acc < curr_score:\n",
    "        LOO_max_acc = curr_score\n",
    "        LOO_max_acc_k = k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c08b428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold_max_acc = 0\n",
    "skfold_max_acc_k = 0\n",
    "for k in range(1, 51):\n",
    "    KNC.n_neighbors = k\n",
    "    curr_score = cross_val_score(KNC, wine.data, wine.target, cv=StratifiedKFold(shuffle=True, random_state=42), scoring='accuracy').mean()\n",
    "#     print(curr_score)\n",
    "    if skfold_max_acc < curr_score:\n",
    "        skfold_max_acc = curr_score\n",
    "        skfold_max_acc_k = k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0c4afff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная точность классификации при использовании Kfold: 0.7304761904761905 при k = 1\n",
      "Максимальная точность классификации при использовании LOO: 0.7696629213483146 при k = 1\n",
      "Максимальная точность классификации при использовании SKfold: 0.7185714285714285 при k = 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Максимальная точность классификации при использовании Kfold: {kfold_max_acc} при k = {kfold_max_acc_k}')\n",
    "print(f'Максимальная точность классификации при использовании LOO: {LOO_max_acc} при k = {LOO_max_acc_k}')\n",
    "print(f'Максимальная точность классификации при использовании SKfold: {skfold_max_acc} при k = {skfold_max_acc_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2826ec6",
   "metadata": {},
   "source": [
    "Таким образом, лучшие результаты показал метод ближайших соседей при числе соседей равном одному и использованием LeaveOneOut кросс-валидации. При этом при всех способах валидации лучший результат получается при одном соседе, то есть элементу просто присваивается тот класс, который имеет ближайший к нему сосед с известным классом.\n",
    "\n",
    "Проведем масштабирование признаков (wine.data -> sklearn.preprocessing.scale(wine.data)) и проделаем то же самое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "67a5a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После масштабирования признаков\n",
      "Максимальная точность классификации при использовании Kfold: 0.9776190476190475 при k = 29\n",
      "Максимальная точность классификации при использовании LOO: 0.9831460674157303 при k = 36\n",
      "Максимальная точность классификации при использовании SKfold: 0.9776190476190475 при k = 13\n"
     ]
    }
   ],
   "source": [
    "kfold_max_acc = 0\n",
    "kfold_max_acc_k = 0\n",
    "for k in range(1, 51):\n",
    "    KNC.n_neighbors = k\n",
    "    curr_score = cross_val_score(KNC, scale(wine.data), wine.target, cv=KFold(shuffle=True, random_state=42), scoring='accuracy').mean()\n",
    "    if kfold_max_acc < curr_score:\n",
    "        kfold_max_acc = curr_score\n",
    "        kfold_max_acc_k = k\n",
    "        \n",
    "LOO_max_acc = 0\n",
    "LOO_max_acc_k = 0\n",
    "for k in range(1, 51):\n",
    "    KNC.n_neighbors = k\n",
    "    curr_score = cross_val_score(KNC, scale(wine.data), wine.target, cv=LeaveOneOut(), scoring='accuracy').mean()\n",
    "    if LOO_max_acc < curr_score:\n",
    "        LOO_max_acc = curr_score\n",
    "        LOO_max_acc_k = k\n",
    "\n",
    "skfold_max_acc = 0\n",
    "skfold_max_acc_k = 0\n",
    "for k in range(1, 51):\n",
    "    KNC.n_neighbors = k\n",
    "    curr_score = cross_val_score(KNC, scale(wine.data), wine.target, cv=StratifiedKFold(shuffle=True, random_state=42), scoring='accuracy').mean()\n",
    "    if skfold_max_acc < curr_score:\n",
    "        skfold_max_acc = curr_score\n",
    "        skfold_max_acc_k = k\n",
    "\n",
    "print('После масштабирования признаков')\n",
    "print(f'Максимальная точность классификации при использовании Kfold: {kfold_max_acc} при k = {kfold_max_acc_k}')\n",
    "print(f'Максимальная точность классификации при использовании LOO: {LOO_max_acc} при k = {LOO_max_acc_k}')\n",
    "print(f'Максимальная точность классификации при использовании SKfold: {skfold_max_acc} при k = {skfold_max_acc_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88784393",
   "metadata": {},
   "source": [
    "Видим значительное увеличение точности работы всех трех методов, потому что после нормализации все признаки имеют один порядок и большие значения не так влияют на расстояния. Вообще, для использования метода k ближайших соседей лучше всегда применять нормализацию. Все методы дали очень хороший близкий к единице результат, однако LeaveOneOut кросс-валидация осталась лучшей из трех. Также стоит отметить изменение оптимального числа соседей (смотри вывод ячейки выше)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
